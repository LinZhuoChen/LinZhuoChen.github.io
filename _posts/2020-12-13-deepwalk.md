---
title: deepwalk 算法
categories: graph embedding
tags:
- 推荐系统
---

图嵌入 (Graph Embedding)  技术是推荐系统中的重要技术，在推荐系统、计算广告领域中十分流行。互联网场景中，数据对象之间大多数呈现图结构。如果能将图中的节点进行embedding，对推荐系统来说非常具有价值。本篇文章将介绍一种经典的Graph Embedding的方法：DeepWalk。

### Deepwalk 介绍

在NLP任务中，word2vec是一种常用的Word embedding方法，该方法通过训练数据中词与词之间的共现关系，习得词语的低维稠密向量表示(embedding)。Deepwalk则通过图中节点与节点之间的共现关系，来习得节点的embedding表示。Deepwalk通过随机游走 (Random walk)的方式，将Graph embedding与Word embedding的方法联系起来。Deepwalk算法主要思想是，通过在图结构上的随机游走，生成大量的序列，然后将生成的序列通过word2vec模型生成对应的embedding。
我们接下来将介绍Deepwalk的方法细节。

### Deepwalk 流程

![](/images/deepwalk.png)

<center>图1 Deepwalk 算法的过程，图片修改自[1]。</center>

图 1展示了Deepwalk算法的主要流程。我们接下来将详细介绍。**首先，我们需要获取用户与物品的交互序列**，如图 1(a)所示。该序列可以为用户观看视频的点赞序列，或者用户购买物品的序列。**接着我们需要根据用户产生的序列，生成物品关系图**，如图 1(b)所示。图 1(a)中U1先后与物品D与物品A发生了交互，那么则产生一条由物品D指向物品A的有向边。如果产生了多条相同的有向边，则该边的权重被加强。**之后我们使用随机游走的方式随机选取初始点，来对图中的节点进行采样并生成对应的序列，**如图1 (c)所示。其中随机游走的次数和窗口长度属于可调节的超参数。对于有向有权图，随机采样的跳转概率为跳转边的权重占所有相关出边权重之和的比例。**最后，我们使用word2vec (skip-gram)产生对应物品节点的embedding**。

Deepwalk 通过随机游走的方式，建立起了Graph embedding与Word embedding之间的联系。使用随机游走有以下优点：

1. **并行性**：多个随机游走可以并行实现，大大减少了采样的时间。
2. **适应性**：可以动态适应网络的局部变化。网络的局部变化只会影响到部分采样路径，因此网络的变化过程中不需要整体重新计算。

### 总结

总的来说，Deepwalk算法的流程如下：

1. 获取用户与物品的交互序列。

2. 依据生成的交互序列，生成对应的物品关系图。

3. 使用随机游走的方法产生物品序列。

4. 将生成的序列通过word2vec模型进行embedding。

在推荐系统中，我们可以利用deepwalk算法产生物品embedding向量的相似性，来实现特定的功能。例如召回层，相似物品推荐等功能。同时我们也可以将该向量作为物品特征的一部分，输入到排序层模型中参与训练。

### 参考资料

\[1\]: Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba (Alibaba 2018)

\[2\]: DeepWalk: Online Learning of Social Representations (SBU 2014)

\[3\]: [深度学习中不得不学的Graph Embedding方法](https://zhuanlan.zhihu.com/p/64200072)

\[4\]: [【Graph Embedding】DeepWalk：算法原理，实现和应用](https://zhuanlan.zhihu.com/p/56380812)

